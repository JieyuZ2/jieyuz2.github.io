(\* denotes equal contribution, = denotes student I mentor)
### AI Agents
- [Training Language Model Agents without Modifying Language Models](https://arxiv.org/abs/2402.11359)
<br>Shaokun Zhang\*, **Jieyu Zhang\***, Jiale Liu, Linxin Song, Chi Wang, Ranjay Krishna, Qingyun Wu.
<br>*ICML 2024*
- [EcoAssistant: Using LLM Assistant More Affordably and Accurately](https://arxiv.org/abs/2310.03046)
<br>**Jieyu Zhang**, Ranjay Krishna, Ahmed Awadallah, Chi Wang.
<br>*LLM Agents @ ICLR 2024*
- [AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework](https://arxiv.org/abs/2308.08155)
<br>Qingyun Wu, Gagan Bansal, **Jieyu Zhang**, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, Ahmed Awadallah, Ryen White, Doug Burger, Chi Wang
<br><ins>*LLM Agents @ ICLR 2024*</ins> <font color=red>Best Paper</font> 
<br><a href="https://github.com/microsoft/autogen" style="color: red; text-decoration: underline">Github 25,000+ Star & 3,700+ Fork</a>

****

### Model Evaluation
- [m&m's: A Benchmark to Evaluate Tool-Use for multi-step multi-modal Tasks](https://arxiv.org/abs/2403.11085)
<br>Zixian Ma, Weikai Huang, **Jieyu Zhang**, Tanmay Gupta, Ranjay Krishna.
- [SciBench: Evaluating College-Level Scientific Problem-Solving Abilities of Large Language Models](https://arxiv.org/abs/2307.10635)
<br>Xiaoxuan Wang\*, Ziniu Hu\*, Pan Lu\*, Yanqiao Zhu\*, **Jieyu Zhang**, Satyen Subramaniam, Arjun R. Loomba, Shichang Zhang, Yizhou Sun, Wei Wang
<br>*ICML 2024*
<br><a href="https://www.nature.com/articles/d41586-023-03507-3" style="color: red; text-decoration: underline">Nature News Feature</a>
- [SugarCrepe: Fixing Hackable Benchmarks for Vision-Language Compositionality](https://arxiv.org/abs/2306.14610)
<br>Cheng-Yu Hsieh\*, **Jieyu Zhang\***, Zixian Ma, Aniruddha Kembhavi, Ranjay Krishna.
<br>*NeurIPS 2023*
- [WRENCH: A Comprehensive Benchmark for Weak Supervision](https://arxiv.org/abs/2109.11377)
<br>**Jieyu Zhang**, Yue Yu, Yinghao Li, Yujing Wang, Yaming Yang, Mao Yang, Alexander Ratner.
<br>*NeurIPS 2021* <font color=red>Oral Presentation</font>

****

### Data Curation
- [DataComp: In Search of the Next Generation of Multimodal Datasets](https://arxiv.org/abs/2304.14108)
<br>34 authors.
<br>*NeurIPS 2023* <font color=red>Oral Presentation</font>
- [On the Trade-off of Intra-/Inter-class Diversity for Supervised Pre-training](https://arxiv.org/abs/2305.12224)
<br>**Jieyu Zhang\***, Bohan Wang\*, Zhengyu Hu, Pang Wei Koh, Alexander Ratner.
<br>*NeurIPS 2023*
- [Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias](https://arxiv.org/abs/2306.15895)
<br>Yue Yu\*, Yuchen Zhuang\*, **Jieyu Zhang\***, Yu Meng, Alexander Ratner, Ranjay Krishna, Jiaming Shen, Chao Zhang.
<br>*NeurIPS 2023*

****

### Data Labeling
- [Leveraging Instance Features for Label Aggregation in Programmatic Weak Supervision](https://arxiv.org/abs/2210.02724)
<br>**Jieyu Zhang\***, Linxin Song=\*, Alexander Ratner.
<br>*AISTATS 2023*
- [Characterizing the Impacts of Semi-supervised Learning for Weak Supervision](https://openreview.net/forum?id=Z8TjsPFBSx)
<br>Jeffrey Li, **Jieyu Zhang**, Ludwig Schmidt, Alexander Ratner.
<br>*NeurIPS 2023*
- [Understanding Programmatic Weak Supervision via Source-aware Influence Function](https://arxiv.org/abs/2205.12879)
<br>**Jieyu Zhang\***, Haonan Wang\*, Cheng-Yu Hsieh, Alexander Ratner.
<br>*NeurIPS 2022*
- [Creating Training Sets via Weak Indirect Supervision](https://arxiv.org/abs/2110.03484)
<br>**Jieyu Zhang**, Bohan Wang, Xiangchen Song, Yujing Wang, Yaming Yang, Jing Bai, Alexander Ratner.
<br>*ICLR 2022*
- [Nemo: Guiding and Contextualizing Weak Supervision for Interactive Data Programming](https://arxiv.org/abs/2203.01382)
<br>Cheng-Yu Hsieh, **Jieyu Zhang**, Alexander Ratner.
<br>*VLDB 2022*

****
